{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fELG9vDJuJdc"
   },
   "source": [
    "# seq2seq: Data Preparation\n",
    "\n",
    "Abdulhakim Alnuqaydan, Ali Kadhim, Sergei Gleyzer, Harrison Prosper\n",
    "\n",
    "July 2021\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "  1. Read the sequence pairs from __data/seq2seq_data.txt__.\n",
    "  1. Exclude sequences with complex numbers and with Taylor series expansions longer than 1000 characters.\n",
    "  1. Write the filtered sequences to __data/seq2seq_data_count.txt__, where count is either 10,000 or 60,000 sequences.\n",
    "  1. Read filtered data and delimit source (i.e, input) and target (i.e., output) sequences with a tab and newline at the start and end of each sequence, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GwFXx5YluJde"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# symbolic symbols\n",
    "from sympy import exp, \\\n",
    "    cos, sin, tan, \\\n",
    "    cosh, sinh, tanh, ln\n",
    "x = sp.Symbol('x')\n",
    "\n",
    "from IPython.display import display\n",
    "    \n",
    "# enable pretty printing of equations\n",
    "sp.init_printing(use_latex='mathjax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file: data/seq2seq_data_10000.txt\n",
      "output file: data/seq2seq_data_42000.txt\n"
     ]
    }
   ],
   "source": [
    "of_order    = re.compile(' [+] O[(]x[*][*]5.*[)]')\n",
    "non_trivial = re.compile(r'(exp|cos|sin|tan|ln|log)[(].*\\bx\\b')\n",
    "add_count   = re.compile('_data')\n",
    "def filterData(inpfile='data/seq2seq_data.txt',\n",
    "               num_seq=50000,  # number of sequences\n",
    "               min_len=5,\n",
    "               max_len=1000):  # maximum length of sequence pairs\n",
    "    \n",
    "    data = open(inpfile).readlines()\n",
    "    \n",
    "    # eliminate expressions involving complex numbers\n",
    "    data = filter(lambda d: d.find('I') < 0, data)\n",
    "    data = list(data)\n",
    "\n",
    "    # strip away O(...), that is, of order..\n",
    "    data = [of_order.sub('', d) for d in data]\n",
    " \n",
    "    # split pairs\n",
    "    data = [ d.split('\\t') for d in data ]\n",
    "\n",
    "    # eliminate expressions that do not involve x, exp, cos etc.\n",
    "    data = filter(lambda d: \n",
    "                  (len(non_trivial.findall(d[0])) > 0) and \\\n",
    "                  (len(non_trivial.findall(d[1])) > 0), data)\n",
    "    data = list(data)\n",
    " \n",
    "    # keep expressions that are >= min_len characters long\n",
    "    data = filter(lambda d: \n",
    "                  (len(d[0]) >= min_len) and (len(d[1]) >= min_len),\n",
    "                  data)\n",
    "    data = list(data)\n",
    "                  \n",
    "    # keep expressions that are <= max_len characters long\n",
    "    data = filter(lambda d: \n",
    "                  (len(d[0]) <= max_len) and (len(d[1]) <= max_len), \n",
    "                  data)\n",
    "    data = list(data)\n",
    "    \n",
    "    N = min(num_seq, len(data))\n",
    "    outfile = add_count.sub('_data_%d' % N, inpfile)\n",
    "    print('output file:', outfile)\n",
    "    \n",
    "    data = ['\\t'.join(d) for d in data]\n",
    "    open(outfile, 'w').writelines(data[:N])\n",
    "    \n",
    "filterData(num_seq=10000)\n",
    "filterData(num_seq=42000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map sequences to lists of indices\n",
    "\n",
    "  1. Split data into a train, validation, and test set.\n",
    "  1. Create a token (i.e., a character) to index map from training data.\n",
    "  1. Map sequences to arrays of indices.\n",
    "  1. Implement custom DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting seq2sequtil.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile seq2sequtil.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "# symbolic symbols\n",
    "from sympy import Symbol, exp, \\\n",
    "    cos, sin, tan, \\\n",
    "    cosh, sinh, tanh, ln\n",
    "x = Symbol('x')\n",
    "\n",
    "class Seq2SeqDataPreparer:\n",
    "    '''\n",
    "    This class maps the source (i.e., input) and target (i.e, output) \n",
    "    sequences of characters into sequences of indices. The source data \n",
    "    are split into x_train, x_valid, and x_test sets and similarly for \n",
    "    the target data.\n",
    "    \n",
    "    Create a data preparer using\n",
    "    \n",
    "    dd = Seq2SeqDataPreparer(X, Y, fractions)\n",
    "    \n",
    "    where,\n",
    "\n",
    "      fractions:    a 2-tuple containing the three-way split of data.\n",
    "                    e.g.: (40/42, 41/42) means split the data as follows\n",
    "                    (40000, 1000, 1000)\n",
    "    '''\n",
    "    def __init__(self, X, Y,\n",
    "                 fractions=[40/42, 41/42]): \n",
    "        \n",
    "        self.fractions = fractions\n",
    "        \n",
    "        # Get maximum sequence length for input expressions\n",
    "        self.x_max_seq_len =  max([len(z) for z in X])\n",
    "        \n",
    "        # Get maximum sequence length for target expressions\n",
    "        self.y_max_seq_len =  max([len(z) for z in Y])\n",
    "        \n",
    "        # get length of splits into train, valid, test\n",
    "        N = int(len(X)*fractions[0])\n",
    "        M = int(len(X)*fractions[1])\n",
    "        \n",
    "        # Create token to index map for source sequences\n",
    "        t = self.token_tofrom_index(X[:N])\n",
    "        self.x_token2index, self.x_index2token = t\n",
    "        \n",
    "        # Create token to index map for target sequences\n",
    "        t = self.token_tofrom_index(Y[:N])\n",
    "        self.y_token2index,self.y_index2token = t\n",
    "        \n",
    "        # Structure data into a list of blocks, where each block\n",
    "        # comprises a tuple (x_data, y_data) whose elements have\n",
    "        #   x_data.shape: (x_seq_len, batch_size)\n",
    "        #   y_data.shape: (y_seq_len, batch_size)\n",
    "        #\n",
    "        # The sequence and batch sizes can vary from block to block.\n",
    "        \n",
    "        self.train_data, self.n_train = self.code_data(X[:N], Y[:N])         \n",
    "        self.valid_data, self.n_valid = self.code_data(X[N:M],Y[N:M])\n",
    "        self.test_data,  self.n_test  = self.code_data(X[M:], Y[M:])\n",
    "\n",
    "    def __del__(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        n  = 0\n",
    "        n += self.n_train\n",
    "        n += self.n_valid\n",
    "        n += self.n_test\n",
    "        return n\n",
    "    \n",
    "    def __str__(self):\n",
    "        s  = ''\n",
    "        s += 'number of seq-pairs (train): %8d\\n' % self.n_train\n",
    "        s += 'number of seq-pairs (valid): %8d\\n' % self.n_valid\n",
    "        s += 'number of seq-pairs (test):  %8d\\n' % self.n_test\n",
    "        s += '\\n'\n",
    "        s += 'number of source tokens:     %8d\\n' % \\\n",
    "        len(self.x_token2index)\n",
    "        s += 'max source sequence length:  %8d\\n' % \\\n",
    "        self.x_max_seq_len\n",
    "        \n",
    "        try:\n",
    "            s += '\\n'\n",
    "            s += 'number of target tokens:     %8d\\n' % \\\n",
    "            len(self.y_token2index)\n",
    "            s += 'max target sequence length:  %8d' % \\\n",
    "            self.y_max_seq_len\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return s\n",
    "         \n",
    "    def num_tokens(self, which='source'):\n",
    "        if which[0] in ['s', 'i']:\n",
    "            return len(self.x_token2index)\n",
    "        else:\n",
    "            return len(self.y_token2index)\n",
    "    \n",
    "    def max_seq_len(self, which='source'):\n",
    "        if which[0] in ['s', 'i']:\n",
    "            return self.x_max_seq_len\n",
    "        else:\n",
    "            return self.y_max_seq_len\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        # map list of indices to a list of tokens\n",
    "        return ''.join([self.y_index2token[i] for i in indices])\n",
    "\n",
    "    def token_tofrom_index(self, expressions):\n",
    "        chars = set()\n",
    "        chars.add(' ')  # for padding\n",
    "        chars.add('?')  # for unknown characters\n",
    "        for expression in expressions:\n",
    "            for char in expression:\n",
    "                chars.add(char)\n",
    "        chars = sorted(list(chars))\n",
    "        \n",
    "        char2index = dict([(char, i) for i, char in enumerate(chars)])\n",
    "        index2char = dict([(i, char) for i, char in enumerate(chars)])\n",
    "        return (char2index, index2char)\n",
    "       \n",
    "    def get_block_indices(self, X, Y):\n",
    "        # X, and Y are just arrays of strings.\n",
    "        #\n",
    "        # 1. Following Matthew Andrews' suggestion double sort \n",
    "        #    expressions, first with targets then sources. But, also\n",
    "        #    note the ordinal values \"i\" of the expressions in X, Y.\n",
    "        sizes = [(len(a), len(b), i) \n",
    "                 for i, (a, b) in enumerate(zip(Y, X))]\n",
    "        sizes.sort()\n",
    "  \n",
    "        # 2. Find ordinal values (indices) of all expression pairs \n",
    "        #    for which the sources are the same length as are the\n",
    "        #    targets.\n",
    "     \n",
    "        block_indices = []\n",
    "        n, m, i  = sizes[0] # n, m, i = len(source), len(target), index\n",
    "        previous = (n, m)\n",
    "        indices  = [i] # cache index of first expression\n",
    "        \n",
    "        for n, m, i in sizes[1:]: # skip first expression\n",
    "            \n",
    "            size = (n, m)\n",
    "            \n",
    "            if size == previous:\n",
    "                indices.append(i) # cache index of expression\n",
    "            else:\n",
    "                # found a new boundary, so save previous \n",
    "                # set of indices...\n",
    "                block_indices.append(indices)\n",
    "                \n",
    "                # ...and start a new list of indices\n",
    "                indices = [i]\n",
    "\n",
    "            previous = size\n",
    "            \n",
    "        # cache expression indices of last block\n",
    "        block_indices.append(indices)\n",
    "        \n",
    "        return block_indices\n",
    "    \n",
    "    def make_block(self, expressions, indices, token2index, unknown):\n",
    "        \n",
    "        # batch size of current block\n",
    "        batch_size = len(indices)\n",
    "        \n",
    "        # By construction, all expressions of a block have \n",
    "        # the same length\n",
    "        seq_len = len(expressions[indices[0]])\n",
    "        \n",
    "        # Create an empty block of correct shape and size\n",
    "        data    = np.zeros((seq_len, batch_size), dtype='long')\n",
    "        #print('seq_len, batch_size: (%d, %d)' % (seq_len, batch_size))\n",
    "        \n",
    "        # loop over expressions for current block\n",
    "        # m: ordinal value of expression in current block\n",
    "        # k: ordinal value of expression in original list of expressions\n",
    "        # n: ordinal value of character in a given expression\n",
    "        \n",
    "        for m, k in enumerate(indices):\n",
    "            \n",
    "            expr = expressions[k]\n",
    "            \n",
    "            #print('%5d expr[%d] | %s |' % (m, k, expr[1:-1]))\n",
    "            \n",
    "            # copy coded characters to 2D arrays\n",
    "        \n",
    "            for n, char in enumerate(expr):\n",
    "                #print('\\t\\t(n, m): (%d, %d)' % (n, m))\n",
    "                try:\n",
    "                    data[n, m] = token2index[char]\n",
    "                except:\n",
    "                    data[n, m] = unknown\n",
    "                    \n",
    "        return data\n",
    "    \n",
    "    def code_data(self, X, Y):\n",
    "        # Implement Arvind's idea\n",
    "        \n",
    "        # X, Y consist of delimited strings: \n",
    "        #   \\tab<characters\\newline\n",
    "        \n",
    "        # loop over sequence pairs and convert them to sequences\n",
    "        # of integers using the two token2index maps\n",
    "      \n",
    "        x_space   = self.x_token2index[' ']\n",
    "        x_unknown = self.x_token2index['?']\n",
    "        \n",
    "        y_space   = self.y_token2index[' ']\n",
    "        y_unknown = self.y_token2index['?']\n",
    " \n",
    "        # 1. Get boundaries of blocks containing sequences of \n",
    "        #    the same length.\n",
    "        \n",
    "        block_indices = self.get_block_indices(X, Y)\n",
    "        \n",
    "        # 2. Loop over boundaries and create blocks of coded\n",
    "        #    sequences\n",
    "        \n",
    "        blocks = []\n",
    "        n_data = 0\n",
    "       \n",
    "        for indices in block_indices:\n",
    "\n",
    "            x_data = self.make_block(X, indices, \n",
    "                                     self.x_token2index, x_unknown)\n",
    " \n",
    "            y_data = self.make_block(Y, indices, \n",
    "                                     self.y_token2index, y_unknown)\n",
    "\n",
    "            blocks.append((x_data, y_data))\n",
    "            n = len(indices)\n",
    "            n_data += n\n",
    "        \n",
    "        assert n_data == len(X)\n",
    "        \n",
    "        return blocks, n_data\n",
    "    \n",
    "class Seq2SeqDataLoader:\n",
    "    '''\n",
    "    dataloader = Seq2seqDataLoader(dataset, device, sample=True)    \n",
    "    '''\n",
    "    def __init__(self, dataset, device, sample=True):\n",
    "        self.dataset = dataset\n",
    "        self.device  = device\n",
    "        self.sample  = sample  \n",
    "        self.count   = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        # increment iteration counter\n",
    "        self.count += 1\n",
    "        \n",
    "        if self.count <= len(self.dataset):\n",
    "            \n",
    "            # 1. randomly pick a block or return blocks in order.\n",
    "            if self.sample:\n",
    "                k = np.random.randint(len(self.dataset))\n",
    "            else:\n",
    "                k = self.count-1 # must subtract one!\n",
    "            \n",
    "            # 2. create tensors directly on the device of interest\n",
    "            X = torch.tensor(self.dataset[k][0], \n",
    "                             device=self.device)\n",
    "            \n",
    "            Y = torch.tensor(self.dataset[k][1], \n",
    "                             device=self.device)\n",
    "        \n",
    "            # shape of X and Y: (seq_len, batch_size)\n",
    "            return X, Y\n",
    "        else:\n",
    "            self.count = 0\n",
    "            raise StopIteration\n",
    "        \n",
    "# Delimit each sequence in filtered sequences\n",
    "# The start of sequence (SOS) and end of sequence (EOS) \n",
    "# tokens are \"\\t\" and \"\\n\", respectively.\n",
    "\n",
    "def loadData(inpfile):\n",
    "    # format of data:\n",
    "    # input expression<tab>target expression<newline>\n",
    "    data = [a.split('\\t') for a in open(inpfile).readlines()]\n",
    "    \n",
    "    X, Y = [], []\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        X.append('\\t%s\\n' % x)\n",
    "        # get rid of spaces in target sequence\n",
    "        y = ''.join(y.split())\n",
    "        Y.append('\\t%s\\n' % y)\n",
    "        \n",
    "    print('Example source:')\n",
    "    print(X[-1])\n",
    "    pprint(X[-1])\n",
    "    print('Example target:')\n",
    "    print(Y[-1])\n",
    "    pprint(Y[-1])\n",
    "\n",
    "    return (X, Y)\n",
    "\n",
    "def pprint(expr):\n",
    "    display(eval(expr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a few sequence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source:\n",
      "\ttan(4*x**2-2)/(5*x+1)*sinh(-2*x/7)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{\\tan{\\left(4 x^{2} - 2 \\right)} \\sinh{\\left(\\frac{2 x}{7} \\right)}}{5 x + 1}$"
      ],
      "text/plain": [
       "    ⎛   2    ⎞     ⎛2⋅x⎞ \n",
       "-tan⎝4⋅x  - 2⎠⋅sinh⎜───⎟ \n",
       "                   ⎝ 7 ⎠ \n",
       "─────────────────────────\n",
       "         5⋅x + 1         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example target:\n",
      "\t2*x*tan(2)/7-10*x**2*tan(2)/7+x**3*(7354*tan(2)/1029-8*tan(2)**2/7-8/7)+x**4*(40/7+40*tan(2)**2/7-36770*tan(2)/1029)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x^{4} \\left(5.71428571428571 + \\frac{40 \\tan^{2}{\\left(2 \\right)}}{7} - \\frac{36770 \\tan{\\left(2 \\right)}}{1029}\\right) + x^{3} \\left(\\frac{7354 \\tan{\\left(2 \\right)}}{1029} - \\frac{8 \\tan^{2}{\\left(2 \\right)}}{7} - 1.14285714285714\\right) - \\frac{10 x^{2} \\tan{\\left(2 \\right)}}{7} + \\frac{2 x \\tan{\\left(2 \\right)}}{7}$"
      ],
      "text/plain": [
       "   ⎛                         2                  ⎞      ⎛                   2  \n",
       " 4 ⎜                   40⋅tan (2)   36770⋅tan(2)⎟    3 ⎜7354⋅tan(2)   8⋅tan (2\n",
       "x ⋅⎜5.71428571428571 + ────────── - ────────────⎟ + x ⋅⎜─────────── - ────────\n",
       "   ⎝                       7            1029    ⎠      ⎝    1029          7   \n",
       "\n",
       "                    ⎞       2                    \n",
       ")                   ⎟   10⋅x ⋅tan(2)   2⋅x⋅tan(2)\n",
       "─ - 1.14285714285714⎟ - ──────────── + ──────────\n",
       "                    ⎠        7             7     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seq2sequtil as sq\n",
    "import importlib\n",
    "importlib.reload(sq)\n",
    "inputs, targets = sq.loadData('data/seq2seq_data_10000.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data preparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of seq-pairs (train):     8000\n",
      "number of seq-pairs (valid):     1000\n",
      "number of seq-pairs (test):      1000\n",
      "\n",
      "number of source tokens:           31\n",
      "max source sequence length:        81\n",
      "\n",
      "number of target tokens:           34\n",
      "max target sequence length:       930\n"
     ]
    }
   ],
   "source": [
    "fractions=[8/10, 9/10]\n",
    "db = sq.Seq2SeqDataPreparer(inputs, targets, fractions)\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1\ttorch.Size([25, 5])\ttorch.Size([85, 5])\n",
      "    2\ttorch.Size([46, 2])\ttorch.Size([106, 2])\n",
      "    3\ttorch.Size([62, 1])\ttorch.Size([171, 1])\n",
      "    4\ttorch.Size([62, 1])\ttorch.Size([42, 1])\n",
      "    5\ttorch.Size([42, 1])\ttorch.Size([329, 1])\n",
      "    6\ttorch.Size([47, 1])\ttorch.Size([265, 1])\n",
      "    7\ttorch.Size([34, 1])\ttorch.Size([33, 1])\n",
      "    8\ttorch.Size([55, 2])\ttorch.Size([300, 2])\n",
      "    9\ttorch.Size([57, 1])\ttorch.Size([69, 1])\n",
      "   10\ttorch.Size([24, 3])\ttorch.Size([48, 3])\n",
      "   11\ttorch.Size([13, 2])\ttorch.Size([18, 2])\n",
      "   12\ttorch.Size([38, 1])\ttorch.Size([137, 1])\n",
      "   13\ttorch.Size([35, 2])\ttorch.Size([93, 2])\n",
      "   14\ttorch.Size([68, 1])\ttorch.Size([281, 1])\n",
      "   15\ttorch.Size([64, 3])\ttorch.Size([187, 3])\n",
      "   16\ttorch.Size([51, 1])\ttorch.Size([102, 1])\n",
      "   17\ttorch.Size([24, 1])\ttorch.Size([54, 1])\n",
      "   18\ttorch.Size([22, 1])\ttorch.Size([45, 1])\n",
      "   19\ttorch.Size([59, 1])\ttorch.Size([170, 1])\n",
      "   20\ttorch.Size([44, 1])\ttorch.Size([286, 1])\n",
      "   21\ttorch.Size([67, 1])\ttorch.Size([269, 1])\n",
      "   22\ttorch.Size([53, 1])\ttorch.Size([143, 1])\n",
      "   23\ttorch.Size([63, 1])\ttorch.Size([135, 1])\n",
      "   24\ttorch.Size([53, 3])\ttorch.Size([73, 3])\n",
      "   25\ttorch.Size([54, 2])\ttorch.Size([47, 2])\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_loader = sq.Seq2SeqDataLoader(db.train_data, device)\n",
    "\n",
    "for i, (X, Y) in enumerate(train_loader):\n",
    "    print('%5d\\t%s\\t%s' % (i+1, X.shape, Y.shape))\n",
    "    if i >= 24: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seq2seq_data_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
