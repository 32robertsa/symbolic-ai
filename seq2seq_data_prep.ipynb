{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fELG9vDJuJdc"
   },
   "source": [
    "# seq2seq: Data Preparation\n",
    "\n",
    "Quarks To Cosmos with AI Virtual Conference: July 12-16, 2021, Carnegie Mellon University\n",
    "\n",
    "## Contributors\n",
    "\n",
    "Abdulhakim Alnuqaydan, Ali Kadhim, Sergei Gleyzer, Harrison Prosper\n",
    "\n",
    "## Hackathon Contributors\n",
    "\n",
    "Andrew Roberts, Jessica Howard, Samuel Hori, Arvind Balasubramanian, Xiaosheng Zhao, Michael Andrews\n",
    "\n",
    "July 2021\n",
    "\n",
    "## Description\n",
    "\n",
    "Use an encoder/decoder model built using LSTMs to map symbolic mathematical expressions $f(x)$ to their Taylor series expansions to ${\\cal O}(x^5)$.\n",
    "\n",
    "We've heavily borrowed from Charon Guo's excellent tutorial at:\n",
    "\n",
    "https://charon.me/posts/pytorch/pytorch_seq2seq_1/\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "  1. Read the sequence pairs from __data/seq2seq_data.txt__.\n",
    "  1. Exclude\n",
    "     1. sequences with complex numbers and with Taylor series expansions longer than 1000 characters.\n",
    "     1. trivial source expressions.\n",
    "  1. Write the filtered sequences to __data/seq2seq_data_count.txt__, where count is either 10,000 or 60,000 sequences.\n",
    "  1. Write out __seq2sequtil.py__.\n",
    "  1. Read filtered data and delimit source (i.e, input) and target (i.e., output) sequences with a tab and newline at the start and end of each sequence, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GwFXx5YluJde"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# symbolic symbols\n",
    "from sympy import exp, \\\n",
    "    cos, sin, tan, \\\n",
    "    cosh, sinh, tanh, ln, log, E\n",
    "x = sp.Symbol('x')\n",
    "\n",
    "from IPython.display import display\n",
    "    \n",
    "# enable pretty printing of equations\n",
    "sp.init_printing(use_latex='mathjax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[ \\right]$"
      ],
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reproducing a subtle bug!\n",
    "data = [['a(4*x)','b(x)'], ['1(exp)','2'], ['3(x)','4']]\n",
    "non_trivial = re.compile(r'(a|3)'\\\n",
    "                         '[(].*\\bx\\b')\n",
    "# eliminate expressions that do not involve x, exp, cos etc.\n",
    "data = filter(lambda d: len(non_trivial.findall(d[0])) > 0, data)\n",
    "data = list(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file: data/seq2seq_data_10000.txt\n",
      "output file: data/seq2seq_data_60000.txt\n"
     ]
    }
   ],
   "source": [
    "of_order    = re.compile(' [+] O[(]x[*][*]5.*[)]')\n",
    "# Please note that breaking a raw string does not propagate its \n",
    "# \"rawness\" across the break :(\n",
    "non_trivial = re.compile(r'(exp|cos|sin|tan|ln|log|cosh|sinh|tanh)'\\\n",
    "                         r'[(].*\\bx\\b')\n",
    "add_count   = re.compile('_data')\n",
    "\n",
    "def filterData(inpfile='data/seq2seq_data.txt',\n",
    "               num_seq=60000,  # number of filtered sequence pairs\n",
    "               min_len=5,      # minimum length of a sequence\n",
    "               max_len=1000):  # maximum length of a sequence\n",
    "    \n",
    "    data = open(inpfile).readlines()\n",
    "    \n",
    "    # eliminate expressions involving complex numbers\n",
    "    data = filter(lambda d: d.find('I') < 0, data)\n",
    "    data = list(data)\n",
    "\n",
    "    # strip away O(...) (of order..)\n",
    "    data = [of_order.sub('', d) for d in data]\n",
    " \n",
    "    # split pairs at tab\n",
    "    data = [ d.split('\\t') for d in data ]\n",
    "    #print(data[:5])\n",
    "    \n",
    "    # keep source expressions that involve exp, cos, etc.\n",
    "    # that is, eliminate trivial expressions.\n",
    "    data = filter(lambda d: len(non_trivial.findall(d[0])) > 0, data)\n",
    "    data = list(data)\n",
    " \n",
    "    # keep expressions that are >= min_len characters long\n",
    "    data = filter(lambda d: \n",
    "                  (len(d[0]) >= min_len) and (len(d[1]) >= min_len),\n",
    "                  data)\n",
    "    data = list(data)\n",
    "                  \n",
    "    # keep expressions that are <= max_len characters long\n",
    "    data = filter(lambda d: \n",
    "                  (len(d[0]) <= max_len) and (len(d[1]) <= max_len), \n",
    "                  data)\n",
    "    data = list(data)\n",
    "    \n",
    "    N = min(num_seq, len(data))\n",
    "    #print(len(data))\n",
    "    outfile = add_count.sub('_data_%d' % N, inpfile)\n",
    "    print('output file:', outfile)\n",
    "    \n",
    "    data = ['\\t'.join(d) for d in data]\n",
    "    open(outfile, 'w').writelines(data[:N])\n",
    "    \n",
    "filterData(num_seq=10000)\n",
    "filterData(num_seq=60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map sequences to lists of indices\n",
    "\n",
    "  1. Split data into a train, validation, and test set.\n",
    "  1. Create a token (i.e., a character) to index map from training data.\n",
    "  1. Map sequences to arrays of indices.\n",
    "  1. Implement custom DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting seq2sequtil.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile seq2sequtil.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import display\n",
    "\n",
    "# symbolic symbols\n",
    "from sympy import Symbol, exp, \\\n",
    "    cos, sin, tan, \\\n",
    "    cosh, sinh, tanh, ln, log, E\n",
    "x = Symbol('x')\n",
    "\n",
    "class Seq2SeqDataPreparer:\n",
    "    '''\n",
    "    This class maps the source (i.e., input) and target (i.e, output) \n",
    "    sequences of characters into sequences of indices. The source data \n",
    "    are split into x_train, x_valid, and x_test sets and similarly for \n",
    "    the target data.\n",
    "    \n",
    "    Create a data preparer using\n",
    "    \n",
    "    dd = Seq2SeqDataPreparer(X, Y, fractions)\n",
    "    \n",
    "    where,\n",
    "\n",
    "      fractions:    a 2-tuple containing the three-way split of data.\n",
    "                    e.g.: (50/60, 55/60) means split the data as follows\n",
    "                    (50000, 5000, 5000)\n",
    "    '''\n",
    "    def __init__(self, X, Y,\n",
    "                 fractions=[50/60, 55/60]): \n",
    "        \n",
    "        self.fractions = fractions\n",
    "        \n",
    "        # Get maximum sequence length for input expressions\n",
    "        self.x_max_seq_len =  max([len(z) for z in X])\n",
    "        \n",
    "        # Get maximum sequence length for target expressions\n",
    "        self.y_max_seq_len =  max([len(z) for z in Y])\n",
    "        \n",
    "        # get length of splits into train, valid, test\n",
    "        N = int(len(X)*fractions[0])\n",
    "        M = int(len(X)*fractions[1])\n",
    "        \n",
    "        # Create token to index map for source sequences\n",
    "        t = self.token_tofrom_index(X[:N])\n",
    "        self.x_token2index, self.x_index2token = t\n",
    "        \n",
    "        # Create token to index map for target sequences\n",
    "        t = self.token_tofrom_index(Y[:N])\n",
    "        self.y_token2index,self.y_index2token = t\n",
    "        \n",
    "        # Structure data into a list of blocks, where each block\n",
    "        # comprises a tuple (x_data, y_data) whose elements have\n",
    "        #   x_data.shape: (x_seq_len, batch_size)\n",
    "        #   y_data.shape: (y_seq_len, batch_size)\n",
    "        #\n",
    "        # The sequence and batch sizes can vary from block to block.\n",
    "        \n",
    "        self.train_data, self.n_train = self.code_data(X[:N], Y[:N])         \n",
    "        self.valid_data, self.n_valid = self.code_data(X[N:M],Y[N:M])\n",
    "        self.test_data,  self.n_test  = self.code_data(X[M:], Y[M:])\n",
    "\n",
    "    def __del__(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        n  = 0\n",
    "        n += self.n_train\n",
    "        n += self.n_valid\n",
    "        n += self.n_test\n",
    "        return n\n",
    "    \n",
    "    def __str__(self):\n",
    "        s  = ''\n",
    "        s += 'number of seq-pairs (train): %8d\\n' % self.n_train\n",
    "        s += 'number of seq-pairs (valid): %8d\\n' % self.n_valid\n",
    "        s += 'number of seq-pairs (test):  %8d\\n' % self.n_test\n",
    "        s += '\\n'\n",
    "        s += 'number of source tokens:     %8d\\n' % \\\n",
    "        len(self.x_token2index)\n",
    "        s += 'max source sequence length:  %8d\\n' % \\\n",
    "        self.x_max_seq_len\n",
    "        \n",
    "        try:\n",
    "            s += '\\n'\n",
    "            s += 'number of target tokens:     %8d\\n' % \\\n",
    "            len(self.y_token2index)\n",
    "            s += 'max target sequence length:  %8d' % \\\n",
    "            self.y_max_seq_len\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return s\n",
    "         \n",
    "    def num_tokens(self, which='source'):\n",
    "        if which[0] in ['s', 'i']:\n",
    "            return len(self.x_token2index)\n",
    "        else:\n",
    "            return len(self.y_token2index)\n",
    "    \n",
    "    def max_seq_len(self, which='source'):\n",
    "        if which[0] in ['s', 'i']:\n",
    "            return self.x_max_seq_len\n",
    "        else:\n",
    "            return self.y_max_seq_len\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        # map list of indices to a list of tokens\n",
    "        return ''.join([self.y_index2token[i] for i in indices])\n",
    "\n",
    "    def token_tofrom_index(self, expressions):\n",
    "        chars = set()\n",
    "        chars.add(' ')  # for padding\n",
    "        chars.add('?')  # for unknown characters\n",
    "        for expression in expressions:\n",
    "            for char in expression:\n",
    "                chars.add(char)\n",
    "        chars = sorted(list(chars))\n",
    "        \n",
    "        char2index = dict([(char, i) for i, char in enumerate(chars)])\n",
    "        index2char = dict([(i, char) for i, char in enumerate(chars)])\n",
    "        return (char2index, index2char)\n",
    "       \n",
    "    def get_block_indices(self, X, Y):\n",
    "        # X, and Y are just arrays of strings.\n",
    "        #\n",
    "        # 1. Following Michael Andrews' suggestion double sort \n",
    "        #    expressions, first with targets then sources. But, also\n",
    "        #    note the ordinal values \"i\" of the expressions in X, Y.\n",
    "        sizes = [(len(a), len(b), i) \n",
    "                 for i, (a, b) in enumerate(zip(Y, X))]\n",
    "        sizes.sort()\n",
    "  \n",
    "        # 2. Find ordinal values (indices) of all expression pairs \n",
    "        #    for which the sources are the same length and the\n",
    "        #    targets are the same length. In general, the sources and\n",
    "        #    targets differ in length.\n",
    "     \n",
    "        block_indices = []\n",
    "        n, m, i  = sizes[0] # n, m, i = len(target), len(source), index\n",
    "        previous = (n, m)\n",
    "        indices  = [i] # cache index of first expression\n",
    "        \n",
    "        for n, m, i in sizes[1:]: # skip first expression\n",
    "            \n",
    "            size = (n, m)\n",
    "            \n",
    "            if size == previous:\n",
    "                indices.append(i) # cache index of expression\n",
    "            else:\n",
    "                # found a new boundary, so save previous \n",
    "                # set of indices...\n",
    "                block_indices.append(indices)\n",
    "                \n",
    "                # ...and start a new list of indices\n",
    "                indices = [i]\n",
    "\n",
    "            previous = size\n",
    "            \n",
    "        # cache expression indices of last block\n",
    "        block_indices.append(indices)\n",
    "        \n",
    "        return block_indices\n",
    "    \n",
    "    \n",
    "    def make_block(self, expressions, indices, token2index, unknown):\n",
    "        \n",
    "        # batch size of current block\n",
    "        batch_size = len(indices)\n",
    "        \n",
    "        # By construction, all expressions of a block have \n",
    "        # the same length, so can use the length of first expression\n",
    "        seq_len = len(expressions[indices[0]])\n",
    "        \n",
    "        # Create an empty block of correct shape and size\n",
    "        data    = np.zeros((seq_len, batch_size), dtype='long')\n",
    "        #print('seq_len, batch_size: (%d, %d)' % (seq_len, batch_size))\n",
    "        \n",
    "        # loop over expressions for current block\n",
    "        # m: ordinal value of expression in current block\n",
    "        # k: ordinal value of expression in original list of expressions\n",
    "        # n: ordinal value of character in a given expression\n",
    "        \n",
    "        for m, k in enumerate(indices):\n",
    "            \n",
    "            expr = expressions[k]\n",
    "            \n",
    "            #print('%5d expr[%d] | %s |' % (m, k, expr[1:-1]))\n",
    "            \n",
    "            # copy coded characters to 2D arrays\n",
    "        \n",
    "            for n, char in enumerate(expr):\n",
    "                #print('\\t\\t(n, m): (%d, %d)' % (n, m))\n",
    "                try:\n",
    "                    data[n, m] = token2index[char]\n",
    "                except:\n",
    "                    data[n, m] = unknown\n",
    "                    \n",
    "        return data\n",
    "    \n",
    "    def code_data(self, X, Y):\n",
    "        # Implement Arvind's idea\n",
    "        \n",
    "        # X, Y consist of delimited strings: \n",
    "        #   \\tab<characters\\newline\n",
    "        \n",
    "        # loop over sequence pairs and convert them to sequences\n",
    "        # of integers using the two token2index maps\n",
    "      \n",
    "        x_space   = self.x_token2index[' ']\n",
    "        x_unknown = self.x_token2index['?']\n",
    "        \n",
    "        y_space   = self.y_token2index[' ']\n",
    "        y_unknown = self.y_token2index['?']\n",
    " \n",
    "        # 1. Get blocks containing sequences of the same length.\n",
    "        \n",
    "        block_indices = self.get_block_indices(X, Y)\n",
    "        \n",
    "        # 2. Loop over the indices associated with each block of coded\n",
    "        #    sequences. The indices are the ordinal values of the\n",
    "        #    sequence pairs X and Y.\n",
    "        \n",
    "        blocks = []\n",
    "        n_data = 0\n",
    "       \n",
    "        for indices in block_indices:\n",
    "\n",
    "            x_data = self.make_block(X, indices, \n",
    "                                     self.x_token2index, x_unknown)\n",
    " \n",
    "            y_data = self.make_block(Y, indices, \n",
    "                                     self.y_token2index, y_unknown)\n",
    "\n",
    "            blocks.append((x_data, y_data))\n",
    "            n = len(indices)\n",
    "            n_data += n\n",
    "        \n",
    "        assert n_data == len(X)\n",
    "        \n",
    "        return blocks, n_data\n",
    "    \n",
    "class Seq2SeqDataLoader:\n",
    "    '''\n",
    "    dataloader = Seq2seqDataLoader(dataset, device, sample=True)    \n",
    "    '''\n",
    "    def __init__(self, dataset, device, sample=True):\n",
    "        self.dataset = dataset\n",
    "        self.device  = device\n",
    "        self.sample  = sample  \n",
    "        self.init()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        \n",
    "        # increment iteration counter\n",
    "        self.count += 1\n",
    "        \n",
    "        if self.count <= self.max_count:\n",
    "            \n",
    "            # 1. randomly pick a block or return blocks in order.\n",
    "            if self.sample:\n",
    "                k = np.random.randint(len(self.dataset))\n",
    "            else:\n",
    "                k = self.count-1 # must subtract one!\n",
    "            \n",
    "            # 2. create tensors directly on the device of interest\n",
    "            X = torch.tensor(self.dataset[k][0], \n",
    "                             device=self.device)\n",
    "            \n",
    "            Y = torch.tensor(self.dataset[k][1], \n",
    "                             device=self.device)\n",
    "        \n",
    "            # shape of X and Y: (seq_len, batch_size)\n",
    "            return X, Y\n",
    "        else:\n",
    "            self.count = 0\n",
    "            raise StopIteration\n",
    "            \n",
    "    def init(self, max_count=0, sample=True):\n",
    "        n_data = len(self.dataset)\n",
    "        self.max_count = n_data if max_count < 1 else min(max_count, \n",
    "                                                          n_data)\n",
    "        self.sample= sample\n",
    "        self.count = 0\n",
    "        \n",
    "# Delimit each sequence in filtered sequences\n",
    "# The start of sequence (SOS) and end of sequence (EOS) \n",
    "# tokens are \"\\t\" and \"\\n\", respectively.\n",
    "\n",
    "def loadData(inpfile):\n",
    "    # format of data:\n",
    "    # input expression<tab>target expression<newline>\n",
    "    data = [a.split('\\t') for a in open(inpfile).readlines()]\n",
    "    \n",
    "    X, Y = [], []\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        X.append('\\t%s\\n' % x)\n",
    "        # get rid of spaces in target sequence\n",
    "        y = ''.join(y.split())\n",
    "        Y.append('\\t%s\\n' % y)\n",
    "        \n",
    "    print('Example source:')\n",
    "    print(X[-1])\n",
    "    pprint(X[-1])\n",
    "    print('Example target:')\n",
    "    print(Y[-1])\n",
    "    pprint(Y[-1])\n",
    "\n",
    "    return (X, Y)\n",
    "\n",
    "def pprint(expr):\n",
    "    display(eval(expr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a few sequence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example source:\n",
      "\t(4*x**2-1)*cos(2*x+9)/cosh(7*x**3/7)/(8*x-8)*exp(-5*x**2+1)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\left(4 x^{2} - 1\\right) e^{1 - 5 x^{2}} \\cos{\\left(2 x + 9 \\right)}}{\\left(8 x - 8\\right) \\cosh{\\left(x^{3} \\right)}}$"
      ],
      "text/plain": [
       "                   2             \n",
       "⎛   2    ⎞  1 - 5⋅x              \n",
       "⎝4⋅x  - 1⎠⋅ℯ        ⋅cos(2⋅x + 9)\n",
       "─────────────────────────────────\n",
       "                      ⎛ 3⎞       \n",
       "        (8⋅x - 8)⋅cosh⎝x ⎠       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example target:\n",
      "\tE*cos(9)/8+x*(E*cos(9)/8-E*sin(9)/4)+x**2*(-E*sin(9)/4-5*E*cos(9)/4)+x**3*(13*E*sin(9)/6-5*E*cos(9)/4)+x**4*(247*E*cos(9)/48+13*E*sin(9)/6)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x^{4} \\left(\\frac{247 e \\cos{\\left(9 \\right)}}{48} + \\frac{13 e \\sin{\\left(9 \\right)}}{6}\\right) + x^{3} \\left(\\frac{13 e \\sin{\\left(9 \\right)}}{6} - \\frac{5 e \\cos{\\left(9 \\right)}}{4}\\right) + x^{2} \\left(- \\frac{e \\sin{\\left(9 \\right)}}{4} - \\frac{5 e \\cos{\\left(9 \\right)}}{4}\\right) + x \\left(\\frac{e \\cos{\\left(9 \\right)}}{8} - \\frac{e \\sin{\\left(9 \\right)}}{4}\\right) + \\frac{e \\cos{\\left(9 \\right)}}{8}$"
      ],
      "text/plain": [
       " 4 ⎛247⋅ℯ⋅cos(9)   13⋅ℯ⋅sin(9)⎞    3 ⎛13⋅ℯ⋅sin(9)   5⋅ℯ⋅cos(9)⎞    2 ⎛  ℯ⋅sin(\n",
       "x ⋅⎜──────────── + ───────────⎟ + x ⋅⎜─────────── - ──────────⎟ + x ⋅⎜- ──────\n",
       "   ⎝     48             6     ⎠      ⎝     6            4     ⎠      ⎝     4  \n",
       "\n",
       "9)   5⋅ℯ⋅cos(9)⎞     ⎛ℯ⋅cos(9)   ℯ⋅sin(9)⎞   ℯ⋅cos(9)\n",
       "── - ──────────⎟ + x⋅⎜──────── - ────────⎟ + ────────\n",
       "         4     ⎠     ⎝   8          4    ⎠      8    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seq2sequtil as sq\n",
    "import importlib\n",
    "importlib.reload(sq)\n",
    "inputs, targets = sq.loadData('data/seq2seq_data_10000.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data preparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of seq-pairs (train):     8000\n",
      "number of seq-pairs (valid):     1000\n",
      "number of seq-pairs (test):      1000\n",
      "\n",
      "number of source tokens:           31\n",
      "max source sequence length:        81\n",
      "\n",
      "number of target tokens:           35\n",
      "max target sequence length:       923\n"
     ]
    }
   ],
   "source": [
    "fractions=[8/10, 9/10]\n",
    "db = sq.Seq2SeqDataPreparer(inputs, targets, fractions)\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block\tX.shape             \tY.shape             \n",
      "    0\ttorch.Size([41, 2]) \ttorch.Size([133, 2])\n",
      " 1000\ttorch.Size([52, 1]) \ttorch.Size([244, 1])\n",
      " 2000\ttorch.Size([25, 1]) \ttorch.Size([70, 1]) \n",
      " 3000\ttorch.Size([49, 1]) \ttorch.Size([293, 1])\n",
      " 4000\ttorch.Size([32, 2]) \ttorch.Size([90, 2]) \n",
      "\n",
      "number of blocks: 4685\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_loader = sq.Seq2SeqDataLoader(db.train_data, device)\n",
    "\n",
    "n = 0\n",
    "print('%5s\\t%-20s\\t%-20s' % ('block', 'X.shape', 'Y.shape'))\n",
    "for i, (X, Y) in enumerate(train_loader):\n",
    "    if i % 1000 == 0:\n",
    "        print('%5d\\t%-20s\\t%-20s' % (i, X.shape, Y.shape))\n",
    "    n += 1\n",
    "print(\"\\nnumber of blocks: %d\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seq2seq_data_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
