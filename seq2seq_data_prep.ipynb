{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fELG9vDJuJdc"
   },
   "source": [
    "# seq2seq: Data Preparation\n",
    "\n",
    "Abdulhakim Alnuqaydan, Ali Kadhim, Sergei Gleyzer, Harrison Prosper\n",
    "\n",
    "July 2021\n",
    "\n",
    "This notebook performs the following tasks:\n",
    "  1. Read the sequence pairs from __data/seq2seq_data.txt__.\n",
    "  1. Exclude sequences with complex numbers and with Taylor series expansions longer than 1000 characters.\n",
    "  1. Write the filtered sequences to __data/seq2seq_data_count.txt__, where count is either 10,000 or 60,000 sequences.\n",
    "  1. Read filtered data and delimit source (i.e, input) and target (i.e., output) sequences with a tab and newline at the start and end of each sequence, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GwFXx5YluJde"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# symbolic symbols\n",
    "from sympy import exp, \\\n",
    "    cos, sin, tan, \\\n",
    "    cosh, sinh, tanh, ln\n",
    "x = sp.Symbol('x')\n",
    "\n",
    "from IPython.display import display\n",
    "    \n",
    "# enable pretty printing of equations\n",
    "sp.init_printing(use_latex='mathjax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output file: data/seq2seq_data_10000.txt\n",
      "output file: data/seq2seq_data_60000.txt\n"
     ]
    }
   ],
   "source": [
    "of_order = re.compile(' [+] O[(]x[*][*]5.*[)]')\n",
    "add_count= re.compile('_data')\n",
    "def filterData(inpfile='data/seq2seq_data.txt',\n",
    "               num_seq=60000, # number of sequences\n",
    "               max_len=260): # maximum length of target sequences\n",
    "    \n",
    "    # eliminate instances involving complex numbers\n",
    "    data = filter(lambda d: d.find('I') < 0, open(inpfile).readlines())\n",
    "    data = list(data)\n",
    " \n",
    "    # keep expansions that are less than maxlen characters long\n",
    "    data = filter(lambda d: len(d) < max_len, data)\n",
    "    data = list(data)\n",
    "    \n",
    "    # strip away O(...), that is, of order..\n",
    "    data = [of_order.sub('', d) for d in data]\n",
    "\n",
    "    N = min(num_seq, len(data))\n",
    "    outfile = add_count.sub('_data_%d' % N, inpfile)\n",
    "    print('output file:', outfile)\n",
    "    open(outfile, 'w').writelines(data[:N])\n",
    "    \n",
    "filterData(num_seq=10000, max_len=260)\n",
    "filterData(num_seq=60000, max_len=260)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map sequences to lists of indices\n",
    "\n",
    "  1. Split data into a train, validation, and test set.\n",
    "  1. Create a token (i.e., a character) to index map from training data.\n",
    "  1. Map sequences to arrays of indices.\n",
    "  1. Implement custom DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting seq2sequtil.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile seq2sequtil.py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import display\n",
    "\n",
    "# symbolic symbols\n",
    "from sympy import Symbol, exp, \\\n",
    "    cos, sin, tan, \\\n",
    "    cosh, sinh, tanh, ln\n",
    "x = Symbol('x')\n",
    "\n",
    "class Seq2SeqDataPreparer:\n",
    "    '''\n",
    "    This class maps the source (i.e., input) and target (i.e, output) \n",
    "    sequences of characters into sequences of indices. The source data \n",
    "    are split into x_train, x_valid, and x_test sets and similarly for \n",
    "    the target data.\n",
    "    \n",
    "    Create a data preparer using\n",
    "    \n",
    "    dd = Seq2SeqDataPreparer(X, Y, fractions)\n",
    "    \n",
    "    where the shape of dd.x_* and dd.y_* is \n",
    "       \n",
    "       (max_seq_len, batch_size)\n",
    "       \n",
    "    (* = train, valid, test)\n",
    "    \n",
    "    and where,\n",
    "      size:         number of instances in data set\n",
    "      max_seq_len:  max sequence length (# characters)\n",
    "      fractions:    a 2-tuple containing the three-way split of data.\n",
    "                    e.g.: (5/6, 5.5/6) means split the data as follows\n",
    "                    (50000, 5000, 5000)\n",
    "    Note: max_seq_len in general differ for source and target.\n",
    "    '''\n",
    "    def __init__(self, X, Y,\n",
    "                 fractions=[5/6,5.5/6], \n",
    "                 max_batch_size=128):\n",
    "        \n",
    "        self.fractions = fractions\n",
    "        self.max_batch_size = max_batch_size\n",
    "        \n",
    "        # get maximum sequence length for input expressions\n",
    "        self.x_max_seq_len =  max([len(z) for z in X])\n",
    "        \n",
    "        # get maximum sequence length for target expressions\n",
    "        self.y_max_seq_len =  max([len(z) for z in Y])\n",
    "        \n",
    "        # code data\n",
    "        N = int(len(X)*fractions[0])\n",
    "        M = int(len(X)*fractions[1])\n",
    "        \n",
    "        # create token to index map for source sequences\n",
    "        t = self.token_tofrom_index(X[:N])\n",
    "        self.x_token2index, self.x_index2token = t\n",
    "        \n",
    "        # create token to index map for target sequences\n",
    "        t = self.token_tofrom_index(Y[:N])\n",
    "        self.y_token2index,self.y_index2token = t\n",
    "        \n",
    "        # structure data into a list of blocks, where each block\n",
    "        # comprises a tuple (x_data, y_data) whose elements have\n",
    "        #   x_data.shape: (x_max_seq_len, block_size)\n",
    "        #   y_data.shape: (y_max_seq_len, block_size)\n",
    "        # and block_size <= max_batch_size.\n",
    "        self.train_data = self.code_data(X[:N],  Y[:N])         \n",
    "        self.valid_data = self.code_data(X[N:M], Y[N:M])\n",
    "        self.test_data  = self.code_data(X[M:],  Y[M:])\n",
    "\n",
    "    def __del__(self):\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        # shape (max_seq_len, size)\n",
    "        n  = 0\n",
    "        n += len(self.train_data)\n",
    "        n += len(self.valid_data)\n",
    "        n += len(self.test_data)\n",
    "        return n\n",
    "    \n",
    "    def __str__(self):\n",
    "        s  = ''\n",
    "        s += 'number of seq-pairs (train): %8d\\n'%len(self.x_train)\n",
    "        s += 'number of seq-pairs (valid): %8d\\n'%len(self.x_valid)\n",
    "        s += 'number of seq-pairs (test):  %8d\\n'%len(self.x_test)\n",
    "        s += '\\n'\n",
    "        s += 'number of source tokens:     %8d\\n' % \\\n",
    "        len(self.x_token2index)\n",
    "        s += 'max source sequence length:  %8d\\n' % \\\n",
    "        self.x_max_seq_len\n",
    "        \n",
    "        try:\n",
    "            s += '\\n'\n",
    "            s += 'number of target tokens:     %8d\\n' % \\\n",
    "            len(self.y_token2index)\n",
    "            s += 'max target sequence length:  %8d' % \\\n",
    "            self.y_max_seq_len\n",
    "        except:\n",
    "            pass\n",
    "        return s\n",
    "         \n",
    "    def num_tokens(self, which='source'):\n",
    "        if which[0] in ['s', 'i']:\n",
    "            return len(self.x_token2index)\n",
    "        else:\n",
    "            return len(self.y_token2index)\n",
    "    \n",
    "    def max_seq_len(self, which='source'):\n",
    "        if which[0] in ['s', 'i']:\n",
    "            return self.x_max_seq_len\n",
    "        else:\n",
    "            return self.y_max_seq_len\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        # map list of indices to a list of tokens\n",
    "        return [self.y_index2token[i] for i in indices]\n",
    "\n",
    "    def token_tofrom_index(self, expressions):\n",
    "        chars = set()\n",
    "        chars.add(' ')  # for padding\n",
    "        chars.add('?')  # for unknown characters\n",
    "        for expression in expressions:\n",
    "            for char in expression:\n",
    "                chars.add(char)\n",
    "        chars = sorted(list(chars))\n",
    "        \n",
    "        char2index = dict([(char, i) for i, char in enumerate(chars)])\n",
    "        index2char = dict([(i, char) for i, char in enumerate(chars)])\n",
    "        return (char2index, index2char)\n",
    "        \n",
    "    def code_data(self, X, Y):\n",
    "        # X, Y consist of delimited strings: \\tab<characters\\newline\n",
    "        \n",
    "        # loop over sequence pairs and convert them to sequences\n",
    "        # of integers using the two token2index maps\n",
    "      \n",
    "        x_unknown = self.x_token2index['?']\n",
    "        y_unknown = self.y_token2index['?']\n",
    "        \n",
    "        cdata     = []  \n",
    "        for i, (x_expression, y_expression) in enumerate(zip(X, Y)):\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # map source characters to integers\n",
    "            # ------------------------------------------\n",
    "            x_n = len(x_expression)\n",
    "            source = [0] * x_n \n",
    "            for t, char in enumerate(x_expression):\n",
    "                try:\n",
    "                    source[t] = self.x_token2index[char]\n",
    "                except:\n",
    "                    source[t] = x_unknown\n",
    "            \n",
    "            # ------------------------------------------\n",
    "            # map target characters to integers\n",
    "            # ------------------------------------------\n",
    "            y_n = len(y_expression)\n",
    "            target = [0] * x_n \n",
    "            for t, char in enumerate(y_expression):\n",
    "                try:\n",
    "                    target[t] = self.y_token2index[char]\n",
    "                except:\n",
    "                    target[t] = y_unknown\n",
    "                    \n",
    "            # Structure data as a list of 4-tuples, with the first\n",
    "            # element of the tuple the length of the target sequence,\n",
    "            # which, in this example, tend to be longer than the\n",
    "            # source sequences. We'll sort the 4-tuples into\n",
    "            # ascending order of target sequence length.\n",
    "            cdata.append((y_n, x_n, target, source))\n",
    "         \n",
    "        # ---------------------------------------------------------\n",
    "        # Group data according to length of target sequence\n",
    "        # ---------------------------------------------------------\n",
    "        # 1. Sort sequence pairs according to target sequence lengths    \n",
    "        cdata.sort() \n",
    "        \n",
    "        # 2. Compute number of blocks of data, n_blocks, each of \n",
    "        #    which will have roughly the same sequence lengths.\n",
    "        n_data   = len(cdata)            # number of sequence pairs\n",
    "        l_block  = max_batch_size + 20   # length of blocks\n",
    "        n_blocks = int(n_data / l_block) # number of blocks\n",
    "        # Note: the last block will, in general, have a length >= \n",
    "        #       to the length of the other blocks.\n",
    "        \n",
    "        # 3. Loop over blocks and and pad sequences so that all\n",
    "        #    sequences within a block are of the same length. Do this\n",
    "        #    separately for source and target sequences. The shape of\n",
    "        #    each block is (max_seq_len, block-size), where max_seq_len\n",
    "        #    can change from block to block.\n",
    "    \n",
    "        self.blocks = [0] * n_blocks\n",
    "        for k in range(n_blocks):\n",
    "            \n",
    "            # get block k\n",
    "            \n",
    "            i = k * l_block              # start of block k\n",
    "            if k < n_blocks - 1:\n",
    "                j = i + l_block - 1      # end of block k\n",
    "            else:\n",
    "                j = n_data - 1\n",
    "\n",
    "            block = cdata[i:j]\n",
    "\n",
    "            # get maximum length of target sequence for current block\n",
    "            y_max_seq_len, x_max_seq_len, _, _ = block[-1]\n",
    "\n",
    "            # for current block source sequences need not be ordered\n",
    "            # the same way as the targets, so get maximum of all \n",
    "            # source sequences for current block.\n",
    "            x_max_seq_len = max([x_len for _, x_len, _, _ in block])\n",
    "   \n",
    "            # loop over sequence pairs in current block\n",
    "            # and pad them to the same length, separately for the\n",
    "            # source and target sequences\n",
    "            block_len = len(block)\n",
    "            x_space   = self.x_token2index[' ']\n",
    "            y_space   = self.y_token2index[' ']\n",
    "            \n",
    "            for i, (y_seq_len, x_seq_len, \n",
    "                    y_seq, x_seq) in enumerate(block):\n",
    "                # ------------------------------------------\n",
    "                # create an empty array for source sequences\n",
    "                # ------------------------------------------\n",
    "                x_data = np.zeros((x_max_seq_len, block_len), \n",
    "                                  dtype='long')\n",
    "                \n",
    "                # copy source data\n",
    "                for t, c in enumerate(x_seq): \n",
    "                    x_data[t, i] = c\n",
    "                    \n",
    "                # pad source data\n",
    "                if x_seq_len < x_max_seq_len: \n",
    "                    x_data[t + 1:, i] = x_space\n",
    "                    \n",
    "                # ------------------------------------------\n",
    "                # create an empty array for target sequences\n",
    "                # ------------------------------------------\n",
    "                y_data = np.zeros((y_max_seq_len, block_len), \n",
    "                                  dtype='long')\n",
    "                \n",
    "                for t, c in enumerate(y_seq): \n",
    "                    y_data[t, i] = c\n",
    "                    \n",
    "                if y_seq_len < y_max_seq_len: \n",
    "                    y_data[t + 1:, i] = y_space\n",
    "            \n",
    "            # cache padded data\n",
    "            blocks[k] = (x_data, y_data)\n",
    "            print('block shapes', x_data.shape, y_data.shape)\n",
    "        return blocks\n",
    "    \n",
    "# Dataset class to return source and target \"sentences\"\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    '''\n",
    "    dataset = Seq2SeqDataset(X, Y)\n",
    "    \n",
    "    shape of data: (max_seq_len, size)\n",
    "    '''\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.X[1])\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # shape of output data: (max_seq_len)\n",
    "        return self.X[:,index], self.Y[:,index]\n",
    "    \n",
    "# See tips on how to increase PyTorch performance:\n",
    "# https://towardsdatascience.com/\n",
    "# 7-tips-for-squeezing-maximum-performance-from-pytorch-ca4a40951259\n",
    "\n",
    "class Seq2SeqDataLoader:\n",
    "    '''\n",
    "    dataloader = Seq2seqDataLoader(X, Y, batch_size=128, shuffle=True)\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, X, Y, \n",
    "                 batch_size=128, \n",
    "                 shuffle=False):\n",
    "        self.dataset    = Seq2SeqDataset(X, Y)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle    = shuffle\n",
    "        self.dataloader = DataLoader(self.dataset, \n",
    "                                     batch_size=batch_size, \n",
    "                                     shuffle=shuffle,\n",
    "                                     pin_memory=True)\n",
    "        self.iter = iter(self.dataloader)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        try:\n",
    "            # If GPU is being used, even though the memory is pinned,\n",
    "            # we may still have to transfer these to the GPU explicitly\n",
    "            X, Y  = self.iter.next()\n",
    "            # need shape: (max_seq_len, batch_size)\n",
    "            return X.transpose(0,1), Y.transpose(0,1)\n",
    "        except:\n",
    "            raise StopIteration\n",
    "            \n",
    "    def reset(self):\n",
    "        self.iter = iter(self.dataloader)\n",
    "        \n",
    "# Delimit each sequence in filtered sequences\n",
    "# The start of sequence (SOS) and end of sequence (EOS) \n",
    "# tokens are \"\\t\" and \"\\n\", respectively.\n",
    "\n",
    "def loadData(inpfile):\n",
    "    # format of data:\n",
    "    # input expression<tab>target expression<newline>\n",
    "    data = [a.split('\\t') for a in open(inpfile).readlines()]\n",
    "    \n",
    "    X, Y = [], []\n",
    "    for i, (x, y) in enumerate(data):\n",
    "        X.append('\\t%s\\n' % x)\n",
    "        # get rid of spaces in target sequence\n",
    "        y = ''.join(y.split())\n",
    "        Y.append('\\t%s\\n' % y)\n",
    "        if i % 2000 == 0:\n",
    "            print(i)\n",
    "            # pretty print expressions\n",
    "            pprint(X[-1])\n",
    "            pprint(Y[-1])\n",
    "            print()\n",
    "    return (X, Y)\n",
    "\n",
    "def pprint(expr):\n",
    "    display(eval(expr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display a few sequence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\sinh{\\left(2 x \\right)}$"
      ],
      "text/plain": [
       "-sinh(2⋅x)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{4 x^{3}}{3} - 2 x$"
      ],
      "text/plain": [
       "     3      \n",
       "  4⋅x       \n",
       "- ──── - 2⋅x\n",
       "   3        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2000\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{4 x \\tanh{\\left(\\frac{7 x^{3}}{3} \\right)}}{7}$"
      ],
      "text/plain": [
       "         ⎛   3⎞ \n",
       "         ⎜7⋅x ⎟ \n",
       "-4⋅x⋅tanh⎜────⎟ \n",
       "         ⎝ 3  ⎠ \n",
       "────────────────\n",
       "       7        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{4 x^{4}}{3}$"
      ],
      "text/plain": [
       "    4 \n",
       "-4⋅x  \n",
       "──────\n",
       "  3   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4000\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{2 x^{2} \\sin{\\left(9 x - 1 \\right)}}{9} - \\left(6 x^{2} + 7\\right) \\tanh{\\left(- 4 x^{3} - 7 \\right)}$"
      ],
      "text/plain": [
       "   2                                           \n",
       "2⋅x ⋅sin(9⋅x - 1)   ⎛   2    ⎞     ⎛     3    ⎞\n",
       "───────────────── - ⎝6⋅x  + 7⎠⋅tanh⎝- 4⋅x  - 7⎠\n",
       "        9                                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 9 x^{4} \\sin{\\left(1 \\right)} + x^{3} \\left(- 28 \\tanh^{2}{\\left(7 \\right)} + 2 \\cos{\\left(1 \\right)} + 28\\right) + x^{2} \\left(- \\frac{2 \\sin{\\left(1 \\right)}}{9} + 6 \\tanh{\\left(7 \\right)}\\right) + 7 \\tanh{\\left(7 \\right)}$"
      ],
      "text/plain": [
       "   4           3 ⎛         2                   ⎞    2 ⎛  2⋅sin(1)            ⎞\n",
       "9⋅x ⋅sin(1) + x ⋅⎝- 28⋅tanh (7) + 2⋅cos(1) + 28⎠ + x ⋅⎜- ──────── + 6⋅tanh(7)⎟\n",
       "                                                      ⎝     9                ⎠\n",
       "\n",
       "            \n",
       " + 7⋅tanh(7)\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6000\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{2 x^{2} \\cosh{\\left(2 x^{2} - 8 \\right)}}{3} + \\frac{\\tanh{\\left(- 6 x^{2} - 7 \\right)}}{\\tanh{\\left(\\frac{8 x}{9} \\right)}}$"
      ],
      "text/plain": [
       "   2     ⎛   2    ⎞       ⎛     2    ⎞\n",
       "2⋅x ⋅cosh⎝2⋅x  - 8⎠   tanh⎝- 6⋅x  - 7⎠\n",
       "─────────────────── + ────────────────\n",
       "         3                   ⎛8⋅x⎞    \n",
       "                         tanh⎜───⎟    \n",
       "                             ⎝ 9 ⎠    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - \\frac{4 x^{4} \\sinh{\\left(8 \\right)}}{3} + x^{3} \\left(- \\frac{81 \\tanh^{3}{\\left(7 \\right)}}{2} - 1.77777777777778 + \\frac{16 \\tanh^{2}{\\left(7 \\right)}}{9} + \\frac{2658229 \\tanh{\\left(7 \\right)}}{65610}\\right) + \\frac{2 x^{2} \\cosh{\\left(8 \\right)}}{3} + x \\left(-6.75 - \\frac{8 \\tanh{\\left(7 \\right)}}{27} + \\frac{27 \\tanh^{2}{\\left(7 \\right)}}{4}\\right) - \\frac{9 \\tanh{\\left(7 \\right)}}{8 x}$"
      ],
      "text/plain": [
       "     4              ⎛         3                                2              \n",
       "  4⋅x ⋅sinh(8)    3 ⎜  81⋅tanh (7)                      16⋅tanh (7)   2658229⋅\n",
       "- ──────────── + x ⋅⎜- ─────────── - 1.77777777777778 + ─────────── + ────────\n",
       "       3            ⎝       2                                9             656\n",
       "\n",
       "       ⎞      2             ⎛                           2   ⎞            \n",
       "tanh(7)⎟   2⋅x ⋅cosh(8)     ⎜        8⋅tanh(7)   27⋅tanh (7)⎟   9⋅tanh(7)\n",
       "───────⎟ + ──────────── + x⋅⎜-6.75 - ───────── + ───────────⎟ - ─────────\n",
       "10     ⎠        3           ⎝            27           4     ⎠      8⋅x   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8000\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{\\left(9 x^{3} + 6\\right) \\cos{\\left(\\frac{8 x^{3}}{7} \\right)}}{\\sin{\\left(2 x^{3} - 3 \\right)}}$"
      ],
      "text/plain": [
       "              ⎛   3⎞\n",
       "⎛   3    ⎞    ⎜8⋅x ⎟\n",
       "⎝9⋅x  + 6⎠⋅cos⎜────⎟\n",
       "              ⎝ 7  ⎠\n",
       "────────────────────\n",
       "      ⎛   3    ⎞    \n",
       "   sin⎝2⋅x  - 3⎠    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle x^{3} \\left(- \\frac{9}{\\sin{\\left(3 \\right)}} - \\frac{12 \\cos{\\left(3 \\right)}}{\\sin^{2}{\\left(3 \\right)}}\\right) - \\frac{6}{\\sin{\\left(3 \\right)}}$"
      ],
      "text/plain": [
       " 3 ⎛    9      12⋅cos(3)⎞     6   \n",
       "x ⋅⎜- ────── - ─────────⎟ - ──────\n",
       "   ⎜  sin(3)       2    ⎟   sin(3)\n",
       "   ⎝            sin (3) ⎠         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t(9*x**3+6)*cos(-8*x**3/7)/sin(2*x**3-3)\n",
      "\n",
      "\t-6/sin(3)+x**3*(-9/sin(3)-12*cos(3)/sin(3)**2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import seq2sequtil as sq\n",
    "inputs, targets = sq.loadData('data/seq2seq_data_10000.txt')\n",
    "print(inputs[8000])\n",
    "print(targets[8000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data preparer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Projects/Tutorials/symbolic-ai/seq2sequtil.py\u001b[0m in \u001b[0;36mcode_data\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                     \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_token2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c721825316a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfractions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeq2SeqDataPreparer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfractions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Tutorials/symbolic-ai/seq2sequtil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, X, Y, fractions, max_batch_size)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#   y_data.shape: (y_max_seq_len, block_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# and block_size <= max_batch_size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_data\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Tutorials/symbolic-ai/seq2sequtil.py\u001b[0m in \u001b[0;36mcode_data\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_token2index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# Structure data as a list of 4-tuples, with the first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "fractions=[8/10, 9/10]\n",
    "db = sq.Seq2SeqDataPreparer(inputs, targets, fractions)\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.x_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [(a[0], b[0]) for a, b in zip(db.y_train, db.x_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( 53, \\  8000, \\  7950\\right)$"
      ],
      "text/plain": [
       "(53, 8000, 7950)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(sizes)\n",
    "B = 150\n",
    "K = int(N / B)\n",
    "K, N, K*B "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0\t    0\t  149\t    3     9\t   10    12\n",
      "    1\t  150\t  299\t    9    10\t   12    13\n",
      "    2\t  300\t  449\t   10    11\t   13    14\n",
      "    3\t  450\t  599\t   11    14\t   14    15\n",
      "    4\t  600\t  749\t   14    17\t   15    15\n",
      "    5\t  750\t  899\t   17    18\t   15    16\n",
      "    6\t  900\t 1049\t   18    20\t   16    16\n",
      "    7\t 1050\t 1199\t   20    22\t   16    16\n",
      "    8\t 1200\t 1349\t   22    24\t   16    17\n",
      "    9\t 1350\t 1499\t   24    25\t   17    17\n",
      "   10\t 1500\t 1649\t   25    27\t   17    19\n",
      "   11\t 1650\t 1799\t   27    30\t   19    22\n",
      "   12\t 1800\t 1949\t   30    32\t   22    23\n",
      "   13\t 1950\t 2099\t   32    34\t   23    24\n",
      "   14\t 2100\t 2249\t   34    36\t   24    24\n",
      "   15\t 2250\t 2399\t   36    38\t   24    25\n",
      "   16\t 2400\t 2549\t   38    39\t   25    25\n",
      "   17\t 2550\t 2699\t   39    40\t   25    26\n",
      "   18\t 2700\t 2849\t   41    42\t   26    27\n",
      "   19\t 2850\t 2999\t   42    44\t   27    27\n",
      "   20\t 3000\t 3149\t   44    47\t   27    27\n",
      "   21\t 3150\t 3299\t   47    49\t   27    28\n",
      "   22\t 3300\t 3449\t   49    52\t   28    28\n",
      "   23\t 3450\t 3599\t   52    55\t   28    30\n",
      "   24\t 3600\t 3749\t   55    57\t   30    31\n",
      "   25\t 3750\t 3899\t   57    59\t   31    32\n",
      "   26\t 3900\t 4049\t   59    62\t   32    35\n",
      "   27\t 4050\t 4199\t   62    64\t   35    37\n",
      "   28\t 4200\t 4349\t   64    67\t   37    38\n",
      "   29\t 4350\t 4499\t   67    69\t   38    38\n",
      "   30\t 4500\t 4649\t   69    71\t   38    39\n",
      "   31\t 4650\t 4799\t   71    73\t   39    40\n",
      "   32\t 4800\t 4949\t   73    74\t   40    41\n",
      "   33\t 4950\t 5099\t   74    77\t   41    42\n",
      "   34\t 5100\t 5249\t   77    79\t   42    42\n",
      "   35\t 5250\t 5399\t   79    81\t   42    43\n",
      "   36\t 5400\t 5549\t   81    85\t   43    45\n",
      "   37\t 5550\t 5699\t   85    88\t   45    46\n",
      "   38\t 5700\t 5849\t   88    91\t   46    48\n",
      "   39\t 5850\t 5999\t   92    95\t   48    49\n",
      "   40\t 6000\t 6149\t   95    99\t   49    50\n",
      "   41\t 6150\t 6299\t   99   103\t   50    51\n",
      "   42\t 6300\t 6449\t  103   107\t   51    52\n",
      "   43\t 6450\t 6599\t  107   112\t   52    53\n",
      "   44\t 6600\t 6749\t  112   117\t   53    54\n",
      "   45\t 6750\t 6899\t  117   122\t   54    56\n",
      "   46\t 6900\t 7049\t  122   129\t   56    58\n",
      "   47\t 7050\t 7199\t  129   135\t   58    60\n",
      "   48\t 7200\t 7349\t  135   143\t   60    62\n",
      "   49\t 7350\t 7499\t  143   152\t   62    64\n",
      "   50\t 7500\t 7649\t  152   160\t   64    66\n",
      "   51\t 7650\t 7799\t  160   171\t   66    70\n",
      "   52\t 7800\t 7999\t  172   214\t   70    81\n"
     ]
    }
   ],
   "source": [
    "batches = []\n",
    "for k in range(K):\n",
    "    i = k*B\n",
    "    if k < K - 1:\n",
    "        j = i + B - 1\n",
    "    else:\n",
    "        j = N - 1\n",
    "    imin, jmin = sizes[i]\n",
    "    imax, jmax = sizes[j]\n",
    "    print('%5d\\t%5d\\t%5d\\t%5d %5d\\t%5d %5d' % (k, i, j, \n",
    "                                       imin, imax, jmin, jmax))\n",
    "    #if k > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = np.arange(K, dtype=np.long)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 29,  1, 28, 27,  6, 33, 29, 19, 31, 46, 47,  9, 26, 48, 50,\n",
       "       10, 27, 10])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = np.random.choice(m, 20)\n",
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 29,  1, 28, 27,  6, 33, 29, 19, 31, 46, 47,  9, 26, 48, 50,\n",
       "       10, 27, 10])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = m[ii]\n",
    "nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check data loader and its reset() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAIN = 100\n",
    "BATCH_SIZE = 10\n",
    "train_loader = sq.Seq2SeqDataLoader(db.x_train[:,:N_TRAIN], \n",
    "                                    db.y_train[:,:N_TRAIN], \n",
    "                                    BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 10])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [28,  3,  3, 28, 28,  7,  7, 24,  7,  3],\n",
      "        [23, 14, 14, 23, 23, 21,  3, 25, 21, 10],\n",
      "        [25,  5,  5, 25, 25, 30, 16,  3, 30,  5],\n",
      "        [22, 30, 30,  3, 22, 27,  5, 15, 27, 30]])\n",
      "torch.Size([81, 10])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 3,  3,  7,  7,  7, 28, 28,  7,  7,  7],\n",
      "        [17, 14,  3,  3,  3, 23, 23,  3, 20,  3],\n",
      "        [ 5,  5, 12, 14, 10, 25, 25, 11, 26, 13],\n",
      "        [30, 30,  5,  5,  5,  3, 22,  5, 28,  5]])\n"
     ]
    }
   ],
   "source": [
    "train_loader.reset()\n",
    "for i, (X, Y) in enumerate(train_loader):\n",
    "    print(X.shape)\n",
    "    print(X[:5,:])\n",
    "    if i >= 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([81, 10])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [28,  3,  3, 28, 28,  7,  7, 24,  7,  3],\n",
      "        [23, 14, 14, 23, 23, 21,  3, 25, 21, 10],\n",
      "        [25,  5,  5, 25, 25, 30, 16,  3, 30,  5],\n",
      "        [22, 30, 30,  3, 22, 27,  5, 15, 27, 30]])\n",
      "torch.Size([81, 10])\n",
      "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 3,  3,  7,  7,  7, 28, 28,  7,  7,  7],\n",
      "        [17, 14,  3,  3,  3, 23, 23,  3, 20,  3],\n",
      "        [ 5,  5, 12, 14, 10, 25, 25, 11, 26, 13],\n",
      "        [30, 30,  5,  5,  5,  3, 22,  5, 28,  5]])\n"
     ]
    }
   ],
   "source": [
    "train_loader.reset()\n",
    "for i, (X, Y) in enumerate(train_loader):\n",
    "    print(X.shape)\n",
    "    print(X[:5,:])\n",
    "    if i >= 1: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "seq2seq_data_generator.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
